{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "21bebb46",
   "metadata": {},
   "source": [
    "# Lead Scoring Case Study\n",
    "\n",
    "\n",
    "Steps followed to build the model:\n",
    "1. [Importing Libraries and Data](#1)\n",
    "2. [Data Understanding and Inspection](#2)\n",
    "3. [Data Cleaning](#3)\n",
    "4. [Data Analysis (EDA)](#4)\n",
    "5. [Data Preparation](#5)\n",
    "6. [Test-Train Split](#6)\n",
    "7. [Feature Scaling](#7)\n",
    "8. [Feature Selection](#8)\n",
    "9. [Model Building](#9)\n",
    "10. [Model Evaluation](#10)\n",
    "11. [Predictions on Test Set](#11)\n",
    "12. [Conclusion](#12)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5ddaa18",
   "metadata": {},
   "source": [
    "## <p id=\"1\">1. Importing Libraries and Data</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfdda9a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.graph_objects as go\n",
    "import plotly.io as pio\n",
    "pio.renderers.default = 'iframe'\n",
    "pio.templates.default = \"plotly_dark\"\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import precision_recall_curve\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eb310a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading the leads dataset\n",
    "leads_df = pd.read_csv('Leads.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "359d624b",
   "metadata": {},
   "source": [
    "## <p id=\"2\">2. Data Understanding and Inspection</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f914b97b",
   "metadata": {},
   "outputs": [],
   "source": [
    "leads_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2385f222",
   "metadata": {},
   "outputs": [],
   "source": [
    "leads_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f038f09",
   "metadata": {},
   "source": [
    "find unique values in each column in the data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88a41e4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# display the info of the dataframe\n",
    "leads_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7fdfba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check for columnwise null count\n",
    "leads_df.isnull().sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19b1265b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#columnwise null values count in terms of percentages sorted in descending order\n",
    "round(100*(leads_df.isnull().sum()/len(leads_df.index)), 2).sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9e877dc",
   "metadata": {},
   "source": [
    "<strong><span style=\"color:blue\">Observation:</span></strong>  There are 13 columns with missing values rate > 15%.\n",
    "Columns with high missing values rate can be dropped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c572ee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "leads_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7598e76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# unique values count in each column\n",
    "leads_df.nunique().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a6516b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check duplicate rows\n",
    "leads_df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e642f6a4",
   "metadata": {},
   "source": [
    "<strong><span style=\"color:blue\">Observation:</span></strong>  No duplicate columns found in the dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "492a5a0e",
   "metadata": {},
   "source": [
    "## <p id=\"3\">3. Data Cleaning</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05027ef0",
   "metadata": {},
   "source": [
    "#### Handling Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23763ec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#columnwise null values count in terms of percentages sorted in descending order\n",
    "round(100*(leads_df.isna().mean()), 2).sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a585c048",
   "metadata": {},
   "source": [
    "#### Replacing 'Select' with NaN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "221d1228",
   "metadata": {},
   "source": [
    "Problem statement states that \"Many of the categorical variables have a level called 'Select' which needs to be handled because it is as good as a null value\"\n",
    "\n",
    "Considering the above statement, we will replace the 'Select' values with NaN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24a5147f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find all the column names having value 'Select' in it\n",
    "def find_cols_with_select_val(df):\n",
    "    for col in df.columns:\n",
    "        if df[col].dtype == 'object':\n",
    "            if df[col].str.contains('Select').any():\n",
    "                print(col)                \n",
    "\n",
    "find_cols_with_select_val(leads_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2133eb9",
   "metadata": {},
   "source": [
    "<strong><span style=\"color:blue\">Observation:</span></strong>  There are 4 columns containing 'Select' as a value. We can replace them with NaN as they are not useful for our analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df6be0c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace 'Select' with NaN\n",
    "leads_df = leads_df.replace('Select', np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d464188f",
   "metadata": {},
   "outputs": [],
   "source": [
    "find_cols_with_select_val(leads_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c91ed82",
   "metadata": {},
   "source": [
    "<strong><span style=\"color:blue\">Observation:</span></strong>  Select values are now replaced with NaN values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb5a01d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets check columnwise null ratio again\n",
    "round(100*(leads_df.isna().mean()), 2).sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8742afb",
   "metadata": {},
   "source": [
    "#### Lets consider 40% as the cut off the null values. If the column has more than 40% null values, we will drop the column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57b3e5f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop all the columns with 40% or more missing values\n",
    "\n",
    "leads_df = leads_df.dropna(thresh=0.6*len(leads_df), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c384e32d",
   "metadata": {},
   "outputs": [],
   "source": [
    "leads_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6371257",
   "metadata": {},
   "source": [
    "<strong><span style=\"color:blue\">Observation:</span></strong>  Number of columns in the dataset are now reduced to 30 from 37."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0be521c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# columns with categorical data\n",
    "\n",
    "leads_df_cat = leads_df.select_dtypes(include=['object']).columns\n",
    "print('Number of Categorical Columns: ', len(leads_df_cat))\n",
    "print('Categorical Columns: ', leads_df_cat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9e66563",
   "metadata": {},
   "source": [
    "### Imputing missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b2a0484",
   "metadata": {},
   "outputs": [],
   "source": [
    "# City column has 39.71% missing values.\n",
    "#lets check the value counts and decide what to do with it\n",
    "leads_df['City'].value_counts(normalize=True)*100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e21eeeb5",
   "metadata": {},
   "source": [
    "<strong><span style=\"color:blue\">Observation:</span></strong>  Data is not uniformly distributed. Mumbai has the maximum number of leads. Lets drop the city column as it is skewed towards Mumbai."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2191224",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop city column\n",
    "leads_df.drop('City', axis=1, inplace=True)\n",
    "leads_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "004ca6bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specialization column has 36.58% missing values.\n",
    "# lets check the value counts of the column\n",
    "leads_df['Specialization'].value_counts(normalize=True)*100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc5d52e6",
   "metadata": {},
   "source": [
    "<strong><span style=\"color:blue\">Observation:</span></strong>  Data is uniformly distributed. No outliers are present. Lets create a new category called 'Others'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2841dc37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a new category \"Others\" for the variable \"Specialization\" with all null values\n",
    "# leads_df['Specialization'] = leads_df['Specialization'].replace(np.nan, 'Others')\n",
    "leads_df['Specialization'] = leads_df['Specialization'].fillna('Others')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f567d6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tags column has 36.29% missing values.\n",
    "# lets check the value counts of the column\n",
    "leads_df['Tags'].value_counts(normalize=True)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41f2d899",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Tags and Country column is irrelavant for the model. Hence, dropping it.\n",
    "leads_df.drop(['Tags', 'Country'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0ed4cb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'What matters most to you in choosing a course' column has 29.32% missing values.\n",
    "# lets check the value counts of the column\n",
    "leads_df['What matters most to you in choosing a course'].value_counts(normalize=True)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78594877",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'What matters most to you in choosing a course' column data is highly skewed.\n",
    "# So we are dropping this column.\n",
    "leads_df.drop('What matters most to you in choosing a course', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92cb3262",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'What is your current occupation' has 29.11% missing values\n",
    "# lets check the value counts\n",
    "leads_df['What is your current occupation'].value_counts(normalize=True)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6647954f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets impute the missing values in 'What is your current occupation' with 'Unemployed'\n",
    "leads_df['What is your current occupation'].fillna('Unemployed', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffcedf16",
   "metadata": {},
   "outputs": [],
   "source": [
    "leads_df['TotalVisits'].value_counts(normalize=True)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b87232d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Impute TotalVisits with mode\n",
    "leads_df['TotalVisits'].fillna(leads_df['TotalVisits'].mode()[0], inplace=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68110cde",
   "metadata": {},
   "outputs": [],
   "source": [
    "leads_df['Page Views Per Visit'].value_counts(normalize=True)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdf4ff00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Impute Page Views Per Visit with mode value\n",
    "leads_df['Page Views Per Visit'].fillna(leads_df['Page Views Per Visit'].mode()[0], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cc1c69a",
   "metadata": {},
   "outputs": [],
   "source": [
    "leads_df['Lead Source'].value_counts(normalize=True)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "751dc8e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imputing the Lead Source column with the mode value i.e. Google\n",
    "leads_df['Lead Source'].fillna('Google', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "313e3fce",
   "metadata": {},
   "outputs": [],
   "source": [
    "leads_df['Last Activity'].value_counts(normalize=True)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7775d25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imputing the Last Activity column with the mode value i.e. Email Opened\n",
    "leads_df['Last Activity'].fillna('Email Opened', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18bec4af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets check the unique values in each column\n",
    "leads_df.nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07818f46",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11009a97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# assign column names with 1 unique value to a list\n",
    "cols_with_one_unique_val = [col for col in leads_df.columns if leads_df[col].nunique() == 1]\n",
    "cols_with_one_unique_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "215a74d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# columns with one unique value doesnt contribute to the model building,\n",
    "# lets drop them\n",
    "leads_df.drop(cols_with_one_unique_val, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82cefa62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropping Prospect ID, Lead Number, Last Notable Activity as they do not contribute to the model\n",
    "leads_df.drop(['Prospect ID','Lead Number','Last Notable Activity'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3df9c3a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "leads_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d938a861",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# function to plot count plots for categorical variables\n",
    "def plot_count_plots(dataframe, cols):\n",
    "    plt.figure(figsize=(15, 40))  # Adjust the figure size if needed\n",
    "\n",
    "    for col in cols:\n",
    "        plt.subplot(8, 2, cols.index(col) + 1)\n",
    "        sns.countplot(data=dataframe, x=col)\n",
    "        plt.title(col, fontsize=12)\n",
    "        plt.xticks(rotation=90)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "categorical_col = leads_df.select_dtypes(include=['category', 'object']).columns.tolist()\n",
    "plot_count_plots(leads_df, categorical_col)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8429337",
   "metadata": {},
   "source": [
    "<strong><span style=\"color:blue\">Observation:</span></strong> \n",
    "Following columns are highly skewed\n",
    "- Through Recommendations\n",
    "- Newspaper\n",
    "- Newspaper Article\n",
    "- Digital Advertisement\n",
    "- X Education Forums\n",
    "- Search\n",
    "- Do not Call\n",
    "\n",
    "Since these columns are highly skewed, we can drop these columns as they will not add any value to our analysis.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7425fec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "leads_df.drop(['Do Not Call','Search','Newspaper Article','X Education Forums','Newspaper','Digital Advertisement','Through Recommendations'],axis=1,inplace=True)\n",
    "print(leads_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77e595b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mapping binary categorical variables (Yes/No to 1/0) \n",
    "leads_df['Do Not Email'] = leads_df['Do Not Email'].apply(lambda x: 1 if x =='Yes' else 0)\n",
    "\n",
    "leads_df['A free copy of Mastering The Interview'] = leads_df['A free copy of Mastering The Interview'].apply(lambda x: 1 if x =='Yes' else 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2ed3540",
   "metadata": {},
   "source": [
    "#### Outlier Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afd2005f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# numeric columns\n",
    "numerical_cols = leads_df.select_dtypes(exclude=['category', 'object']).columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d19216d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for col in numerical_cols:\n",
    "    plt.figure(figsize=(6, 4))  # Adjust the figure size if needed\n",
    "\n",
    "    sns.boxplot(data=leads_df[col])\n",
    "\n",
    "    plt.title(f'Box Plot of {col}', fontsize=14)\n",
    "    plt.ylabel('Values')\n",
    "    plt.xlabel(col)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "747d7128",
   "metadata": {},
   "source": [
    "#### Outlier Treatment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55eeb0d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_outlier_treatment(dataframe, column):\n",
    "    Q1 = dataframe[column].quantile(0.25)\n",
    "    Q3 = dataframe[column].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    \n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "\n",
    "    dataframe[column] = np.where(dataframe[column] > upper_bound, upper_bound, dataframe[column])\n",
    "    dataframe[column] = np.where(dataframe[column] < lower_bound, lower_bound, dataframe[column])\n",
    "\n",
    "columns_to_treat = ['TotalVisits', 'Page Views Per Visit']\n",
    "\n",
    "for col in columns_to_treat:\n",
    "    perform_outlier_treatment(leads_df, col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f49a946",
   "metadata": {},
   "outputs": [],
   "source": [
    "leads_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c988ac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "leads_df.describe(percentiles=[.10,.25,.50,.75,.95])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cc368b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "leads_df['Lead Source'].value_counts(normalize=True)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "373df2bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Changing google to Google\n",
    "leads_df['Lead Source'] = leads_df['Lead Source'].replace(\"google\",\"Google\")\n",
    "\n",
    "# Group the values of the column 'Lead Source' into a new value 'Others' if the value count is less than 10 in the column 'Lead Source'\n",
    "category_counts = leads_df['Lead Source'].value_counts()\n",
    "category_names_less_than_10 = category_counts[category_counts < 10].index.tolist()\n",
    "print(category_names_less_than_10)\n",
    "leads_df.loc[leads_df['Lead Source'].isin(category_names_less_than_10), 'Lead Source'] = 'Others'\n",
    "\n",
    "leads_df['Lead Source'].value_counts(normalize=True)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a51bd322",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group the values of the variable 'Last Activity' into a new category called 'Others' if the value count is less than 100\n",
    "\n",
    "category_counts = leads_df['Last Activity'].value_counts()\n",
    "category_names_less_than_100 = category_counts[category_counts < 100].index.tolist()\n",
    "\n",
    "leads_df.loc[leads_df['Last Activity'].isin(category_names_less_than_100), 'Last Activity'] = 'Others'\n",
    "\n",
    "leads_df['Last Activity'].value_counts(normalize=True)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b8d5965",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(leads_df.select_dtypes(include=['category', 'object']).columns.tolist())\n",
    "print(leads_df.select_dtypes(exclude=['category', 'object']).columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ada9acca",
   "metadata": {},
   "outputs": [],
   "source": [
    "leads_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "233b18fe",
   "metadata": {},
   "source": [
    "## <p id=\"4\">4. Data Analysis (EDA)</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2c31f33",
   "metadata": {},
   "source": [
    "#### Univariate Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a59b8076",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# List of columns for which to create count plots\n",
    "cols = [\n",
    "    'Lead Origin', 'Lead Source', 'Last Activity',\n",
    "    'What is your current occupation', 'Do Not Email',\n",
    "    'Converted', 'Specialization',\n",
    "    'A free copy of Mastering The Interview'\n",
    "]\n",
    "\n",
    "\n",
    "sns.set_theme(style=\"dark\")\n",
    "\n",
    "\n",
    "for col in cols:\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    \n",
    "    # Create a count plot\n",
    "    sns.countplot(data=leads_df, x=col)\n",
    "    plt.title(f'Count Plot of {col}')\n",
    "    plt.xlabel(col)\n",
    "    plt.ylabel('Count')\n",
    "    \n",
    "    # Calculate and display percentages on top of the bars\n",
    "    total_counts = leads_df[col].value_counts()\n",
    "    for patch in plt.gca().patches:\n",
    "        x = patch.get_x() + patch.get_width() / 2\n",
    "        y = patch.get_height()\n",
    "        percentage = y / len(leads_df)  # Calculate percentage based on the total number of entries\n",
    "        plt.annotate(f'{percentage:.2%}', (x, y), ha='center', va='bottom')\n",
    "    \n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a12a8f37",
   "metadata": {},
   "source": [
    "<strong><span style=\"color:blue\">Observation:</span></strong>  \n",
    "\n",
    "**Here is the list of features from variables which are present in majority (Converted and Not Converted included)** \n",
    "\n",
    "- **Lead Origin:** \"Landing Page Submission\" identified 53% customers, \"API\" identified 39%. \n",
    "- **Lead Source:** 58% Lead source is from Google & Direct Traffic combined\n",
    "- **Last Activity:** 68% of customers contribution in SMS Sent & Email Opened activities\n",
    "- **Current_occupation:** It has 90% of the customers as Unemployed\n",
    "- **Do Not Email:** 92% of the people has opted that they dont want to be emailed about the course.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5044233",
   "metadata": {},
   "source": [
    "#### Bivariate Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1924e36e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def plot_bivariate_count(data, x_col, y_col):\n",
    "    # Create a cross-tabulation (crosstab) of the two columns\n",
    "    crosstab = pd.crosstab(data[x_col], data[y_col], normalize='index') * 100\n",
    "    count_crosstab = pd.crosstab(data[x_col], data[y_col])\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    \n",
    "    # Define a custom color palette for the count plot bars\n",
    "    custom_palette = sns.color_palette(['#FF8080', '#80FF80'])\n",
    "\n",
    "    \n",
    "    ax = sns.countplot(data=data, x=x_col, hue=y_col, palette=custom_palette)\n",
    "    plt.title(f'Lead Conversion Rate: {x_col}')\n",
    "    plt.xlabel(x_col)\n",
    "    plt.ylabel('Count')\n",
    "    \n",
    "    plt.xticks(rotation=90)  # Rotate x-axis labels by 90 degrees\n",
    "    plt.legend(title=y_col, loc='upper right', labels=['No', 'Yes'])  # Place legend at top right\n",
    "    \n",
    "#     total=len(leads_df[x_col])\n",
    "\n",
    "#     for p in ax.patches:\n",
    "#         text = '{:.1f}%'.format(100*p.get_height()/total)\n",
    "#         x = p.get_x() + p.get_width() / 2.\n",
    "#         y = p.get_height()\n",
    "\n",
    "#         ax.annotate(text, (x,y), ha = 'center', va = 'center', xytext = (0, 5), textcoords = 'offset points')\n",
    "    \n",
    "    # Add percentage labels on top of the bars\n",
    "    all_heights = [[p.get_height() if not pd.isna(p.get_height()) else 0 for p in bars] for bars in ax.containers]\n",
    "\n",
    "    for bars in ax.containers:\n",
    "        for i, p in enumerate(bars):\n",
    "            total = sum(xgroup[i] for xgroup in all_heights)\n",
    "            percentage = f'{(100 * p.get_height() / total) :.1f}%'\n",
    "            ax.annotate(percentage, (p.get_x() + p.get_width() / 2, p.get_height()), size=11, ha='center', va='bottom')\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "cols = [\n",
    "    'Lead Origin', 'Lead Source', 'Last Activity',\n",
    "    'What is your current occupation', 'Do Not Email', 'Specialization',\n",
    "    'A free copy of Mastering The Interview'\n",
    "]\n",
    "\n",
    "for col in cols:\n",
    "    plot_bivariate_count(leads_df, col, 'Converted')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "522e3e4e",
   "metadata": {},
   "source": [
    "<strong><span style=\"color:blue\">Observation:</span></strong>  \n",
    "\n",
    "**Lead Origin:**\n",
    "- About 53% of leads stem from \"Landing Page Submission,\" boasting a conversion rate of 36%.\n",
    "- The \"API\" accounts for approximately 39% of customers, showing a conversion rate of 31%.\n",
    "\n",
    "**Current Occupation:**\n",
    "- Approximately 90% of customers fall under the \"Unemployed\" category, with a conversion rate of 34%.\n",
    "- Despite constituting only 7.6% of the total customer base, \"Working Professionals\" exhibit an impressive 92% conversion rate.\n",
    "\n",
    "**Do Not Email:**\n",
    "- A significant 92% of individuals have chosen not to receive email communications regarding the course.\n",
    "\n",
    "**Lead Source:**\n",
    "- \"Google\" yields a conversion rate of 40% among the 31% of customers from this source.\n",
    "- \"Direct Traffic\" contributes a lower conversion rate of 32% with a customer percentage of 27%.\n",
    "- Although \"Organic Search\" contributes to 37.8% of the conversion rate, it represents only 12.5% of the customer base.\n",
    "- \"Reference\" showcases a remarkable conversion rate of 91%, yet it comprises merely around 6% of the customer acquisition.\n",
    "\n",
    "**Last Activity:**\n",
    "- The act of sending an \"SMS\" displays a notably high conversion rate of 63%, driven by 30% of last activities.\n",
    "- \"Email Opened\" encompasses 38% of the customer's recent interactions, accompanied by a conversion rate of 37%.\n",
    "\n",
    "**Specialization:**\n",
    "- \"Marketing Management,\" \"HR Management,\" and \"Finance Management\" emerge as prominent contributors.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07de2aa1",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "num_cols = [ 'TotalVisits', 'Total Time Spent on Website', 'Page Views Per Visit']\n",
    "plt.figure(figsize=(20,15))\n",
    "sns.pairplot(data=leads_df, vars=num_cols, hue=\"Converted\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5c37888",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 5))\n",
    "plt.subplot(1,3,1)\n",
    "sns.boxplot(y = 'TotalVisits', x = 'Converted', data = leads_df)\n",
    "plt.subplot(1,3,2)\n",
    "sns.boxplot(y = 'Page Views Per Visit', x = 'Converted', data = leads_df)\n",
    "plt.subplot(1,3,3)\n",
    "sns.boxplot(y = 'Total Time Spent on Website', x = 'Converted', data = leads_df)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e215cba5",
   "metadata": {},
   "source": [
    "<strong><span style=\"color:blue\">Observation:</span></strong>\n",
    "#### Leads who spent more time on the website had high conversion rate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa181bbb",
   "metadata": {},
   "source": [
    "## <p id=\"5\">5. Data Preparation</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "851bf2a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "leads_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7efbcac",
   "metadata": {},
   "source": [
    "#### Before creating dummy variables lets shorten the columns with large names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d6964fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename 'A free copy of Mastering The Interview' column to 'free_copy' and 'What is your current occupation' to 'occupation'\n",
    "leads_df.rename(columns={'A free copy of Mastering The Interview':'Free_copy','What is your current occupation':'Occupation'},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3224f29a",
   "metadata": {},
   "outputs": [],
   "source": [
    "leads_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d036b464",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = [\"Lead Source\", \"Lead Origin\",\"Last Activity\",\"Specialization\",\"Occupation\"]\n",
    "\n",
    "for i in x:\n",
    "    print(i, len(leads_df[i].value_counts()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50f670cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.get_dummies(leads_df[[\"Lead Origin\",\"Lead Source\",\"Last Activity\",\"Specialization\",\"Occupation\"]], drop_first=True)\n",
    "# print(df.shape)\n",
    "\n",
    "# create dummy variables for categorical variables\n",
    "leads_df = pd.get_dummies(data=leads_df, columns=[\"Lead Source\", \"Lead Origin\",\"Last Activity\",\"Specialization\",\"Occupation\"], drop_first=True)\n",
    "# dropping the first column as k-1 dummies can explain k categories\n",
    "print(df.shape)\n",
    "# leads_df = pd.concat([leads_df, df], axis=1)\n",
    "# print(leads_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5a6dc2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "leads_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cca9c48",
   "metadata": {},
   "outputs": [],
   "source": [
    "leads_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "500f1300",
   "metadata": {},
   "source": [
    "## <p id=\"6\">6. Test-Train Split</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6782ec47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'Converted' is the dependent variable\n",
    "y = leads_df.pop('Converted')\n",
    "\n",
    "# All remaining variable are independent variables\n",
    "X = leads_df\n",
    "\n",
    "print('Before split:',X.shape, y.shape)\n",
    "\n",
    "# Train Test split with 70:30 ratio\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.7, random_state=100)\n",
    "\n",
    "print('After split X data', X_train.shape, X_test.shape)\n",
    "print('After split y data', y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59f3d3df",
   "metadata": {},
   "source": [
    "## <p id=\"7\">7. Feature Scaling</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fb66ee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cols=X_train.select_dtypes(include=['int64','float64']).columns\n",
    "\n",
    "#Use Normalized scaler to scale\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "#Fit and transform training set only\n",
    "X_train[num_cols] = scaler.fit_transform(X_train[num_cols])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "242ca100",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train[num_cols].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16dfd869",
   "metadata": {},
   "outputs": [],
   "source": [
    "# analyse correlation matrix\n",
    "plt.figure(figsize = (50,15))        \n",
    "sns.heatmap(leads_df.corr(),linewidths=0.01,cmap=\"GnBu\",annot=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bae633e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (5,5))        \n",
    "sns.heatmap(leads_df[[\"Lead Source_Facebook\",\"Lead Origin_Lead Import\",\"Lead Origin_Lead Add Form\",\"Lead Source_Reference\"]].corr(),linewidths=0.01,cmap=\"crest\",annot=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22d954dd",
   "metadata": {},
   "source": [
    "<strong><span style=\"color:blue\">Observation:</span></strong>\n",
    "These predictor variables above are very highly correlated with each other near diagonal with (0.98 and 0.85), it is better that we drop one of these variables from each pair as they wonâ€™t add much value to the model. So , we can drop any of them, lets drop `'Lead Origin_Lead Import'` and `'Lead Origin_Lead Add Form'`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fda44ba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop 'Lead Origin_Lead Import' and 'Lead Origin_Lead Add Form' columns as they are highly correlated with 'Lead Source_Facebook' and 'Lead Source_Reference' respectively\n",
    "X_train.drop(['Lead Origin_Lead Import', 'Lead Origin_Lead Add Form'], axis=1, inplace=True)\n",
    "X_test.drop(['Lead Origin_Lead Import', 'Lead Origin_Lead Add Form'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42b47b38",
   "metadata": {},
   "source": [
    "## <p id=\"8\">8. Feature Selection</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe120859",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(X_train.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0abb911",
   "metadata": {},
   "source": [
    "##### Using automated approach to cut down the features\n",
    "Feature ranking with recursive feature elimination(RFE)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c899f338",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets use RFE to reduce variables \n",
    "logreg = LogisticRegression()\n",
    "rfe = RFE(logreg, n_features_to_select=15)            \n",
    "rfe = rfe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a794c3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# all columns\n",
    "X_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acf4621e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 15 features selected by RFE\n",
    "rfe_cols = X_train.columns[rfe.support_].values.tolist()\n",
    "print(rfe_cols)\n",
    "print(X_train.columns[rfe.support_])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8380da81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Features not selected by RFE\n",
    "X_train.columns[~rfe.support_]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "381c8393",
   "metadata": {},
   "source": [
    "##### Manual Elimination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4456d570",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to build a model using statsmodel api - Takes the columns to be selected for model as a parameter\n",
    "def build_model(cols):\n",
    "    X_train_sm = sm.add_constant(X_train[cols])\n",
    "    lm = sm.GLM(y_train,X_train_sm,family = sm.families.Binomial()).fit()  \n",
    "    print(lm.summary())\n",
    "    return lm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "407a6045",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to calculate VIFs and print them -Takes the columns for which VIF to be calculated as a parameter\n",
    "def get_vif(cols):\n",
    "    df1 = X_train[cols]\n",
    "    vif = pd.DataFrame()\n",
    "    vif['Features'] = df1.columns\n",
    "    vif['VIF'] = [variance_inflation_factor(df1.values, i) for i in range(df1.shape[1])]\n",
    "    vif['VIF'] = round(vif['VIF'],2)\n",
    "    print(vif.sort_values(by='VIF',ascending=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4160fcc",
   "metadata": {},
   "source": [
    "## <p id=\"9\">9. Model Building</p>\n",
    "\n",
    "Model Evaulation criteria\n",
    "- p-value < 0.05\n",
    "- VIF < 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c489395",
   "metadata": {},
   "source": [
    "#### Model-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3360f51c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Selected columns for Model 1 - all columns selected by RFE\n",
    "build_model(rfe_cols)\n",
    "get_vif(rfe_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acde318a",
   "metadata": {},
   "source": [
    "<strong><span style=\"color:Blue\">NOTE : </span></strong> \"Occupation_Housewife\" column will be removed from model due to high p-value of 0.999, which is above the accepted threshold of 0.05 for statistical significance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88cd11f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_and_return_element(arr, element):\n",
    "    updated_array = [x for x in arr if x != element]\n",
    "    return updated_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44bc3218",
   "metadata": {},
   "outputs": [],
   "source": [
    "rfe_cols = remove_and_return_element(rfe_cols, 'Occupation_Housewife')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca9b51df",
   "metadata": {},
   "source": [
    "#### Model-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a28bfb7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "build_model(rfe_cols)\n",
    "get_vif(rfe_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cbee201",
   "metadata": {},
   "source": [
    "<strong><span style=\"color:Blue\">NOTE:</span></strong> \"Lead Source_Others\" column will be removed from model due to high p-value of 0.095,  which is above the accepted threshold of 0.05 for statistical significance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3405d250",
   "metadata": {},
   "outputs": [],
   "source": [
    "rfe_cols = remove_and_return_element(rfe_cols, 'Lead Source_Others')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f67ead7e",
   "metadata": {},
   "source": [
    "#### Model-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7afa6db",
   "metadata": {},
   "outputs": [],
   "source": [
    "build_model(rfe_cols)\n",
    "get_vif(rfe_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e09f207f",
   "metadata": {},
   "source": [
    "<strong><span style=\"color:Blue\">NOTE:</span></strong> \"Page Views Per Visit\" column will be removed from model due to high VIF value of 6.34, which is greater than the accepted threshold of 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2536e8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "rfe_cols = remove_and_return_element(rfe_cols, 'Page Views Per Visit')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce172178",
   "metadata": {},
   "source": [
    "#### Model-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e193ce0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "build_model(rfe_cols)\n",
    "get_vif(rfe_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f009a1b5",
   "metadata": {},
   "source": [
    "<strong><span style=\"color:Blue\">NOTE:</span></strong> \"TotalVisits\" column will be removed from model due to high p-value of 0.086, which is above the accepted threshold of 0.05 for statistical significance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e27c3a85",
   "metadata": {},
   "outputs": [],
   "source": [
    "rfe_cols = remove_and_return_element(rfe_cols, 'TotalVisits')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59b14aad",
   "metadata": {},
   "source": [
    "#### Model-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ab3f105",
   "metadata": {},
   "outputs": [],
   "source": [
    "logm = build_model(rfe_cols)\n",
    "get_vif(rfe_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b39c2616",
   "metadata": {},
   "source": [
    "<strong><span style=\"color:Blue\">NOTE:</span></strong> No variable needs to be dropped as they all have significant p-values within the threshold (p-values < 0.05) and all have good VIF values less than 5.\n",
    "- p-values for all variables is less than 0.05\n",
    "- This model looks acceptable as everything is under control (p-values & VIFs).\n",
    "- So we will final our Model 5 for `Model Evaluation`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01101995",
   "metadata": {},
   "source": [
    "## <p id=\"10\">10. Model Evaluation</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51642e7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_sm5 = sm.add_constant(X_train[rfe_cols])\n",
    "\n",
    "# Getting the predicted values on the train set\n",
    "y_train_pred = logm.predict(X_train_sm5)         # giving prob. of getting 1\n",
    "\n",
    "y_train_pred[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af3d2b00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for array\n",
    "y_train_pred = y_train_pred.values.reshape(-1)\n",
    "y_train_pred[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cf7ad94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a dataframe with the actual converted flag and the predicted probabilities\n",
    "\n",
    "y_train_pred_final = pd.DataFrame({'Converted':y_train.values, 'Converted_Prob':y_train_pred})\n",
    "y_train_pred_final['Prospect ID'] = y_train.index\n",
    "y_train_pred_final.head()\n",
    "\n",
    "# y_train.values actual Converted values from df_leads dataset\n",
    "# y_train_pred probability of Converted values predicted by model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6bb64b2",
   "metadata": {},
   "source": [
    "##### Creating new column 'predicted' with 1 if Converted_Prob > 0.5 else 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc3bbb41",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred_final['Predicted'] = y_train_pred_final[\"Converted_Prob\"].map(lambda x: 1 if x > 0.5 else 0)\n",
    "\n",
    "# checking head\n",
    "y_train_pred_final.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0872680",
   "metadata": {},
   "source": [
    "#### Confusion matrix \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb8e6bc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion = metrics.confusion_matrix(y_train_pred_final[\"Converted\"], y_train_pred_final[\"Predicted\"])\n",
    "\n",
    "print(confusion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6aed8a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicted     not_converted    converted\n",
    "# Actual\n",
    "# not_converted        3572      430\n",
    "# converted            844       1622  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2cc685d",
   "metadata": {},
   "source": [
    "#### Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ee52eba",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(metrics.accuracy_score(y_train_pred_final[\"Converted\"], y_train_pred_final[\"Predicted\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee84c54a",
   "metadata": {},
   "source": [
    "#### Metrics beyond simply accuracy\n",
    "- Sensitivity and Specificity\n",
    "- When we have Predicted at threshold 0.5 probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "501bbfbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "TP = confusion[1,1] # true positive \n",
    "TN = confusion[0,0] # true negatives\n",
    "FP = confusion[0,1] # false positives\n",
    "FN = confusion[1,0] # false negatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "073c00ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's see the sensitivity of our logistic regression model\n",
    "print(\"Sensitivity :\",TP / float(TP+FN))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81519776",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let us calculate specificity\n",
    "print(\"Specificity :\",TN / float(TN+FP))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce5e48bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate false postive rate - predicting conversion when customer does not have converted\n",
    "print(FP/ float(TN+FP))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bc06656",
   "metadata": {},
   "outputs": [],
   "source": [
    "# positive predictive value \n",
    "print (TP / float(TP+FP))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a430ce26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Negative predictive value\n",
    "print (TN / float(TN+ FN))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d17f5b9",
   "metadata": {},
   "source": [
    "#### Plotting the ROC Curve\n",
    "\n",
    "An ROC curve demonstrates several things:\n",
    "\n",
    "- It shows the tradeoff between sensitivity and specificity (any increase in sensitivity will be accompanied by a decrease in specificity).\n",
    "- The closer the curve follows the left-hand border and then the top border of the ROC space, the more accurate the test.\n",
    "- The closer the curve comes to the 45-degree diagonal of the ROC space, the less accurate the test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fff214c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# UDF to draw ROC curve \n",
    "def draw_roc( actual, probs ):\n",
    "    fpr, tpr, thresholds = metrics.roc_curve( actual, probs,\n",
    "                                              drop_intermediate = False )\n",
    "    auc_score = metrics.roc_auc_score( actual, probs )\n",
    "    plt.figure(figsize=(5, 5))\n",
    "    plt.plot( fpr, tpr, label='ROC curve (area = %0.2f)' % auc_score )\n",
    "    plt.plot([0, 1], [0, 1], 'k--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate or [1 - True Negative Rate]')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver operating characteristic example')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()\n",
    "\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94f5d18e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr, tpr, thresholds = metrics.roc_curve(y_train_pred_final[\"Converted\"], y_train_pred_final[\"Converted_Prob\"], drop_intermediate = False )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc720353",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drawing ROC curve for Train Set\n",
    "draw_roc(y_train_pred_final[\"Converted\"], y_train_pred_final[\"Converted_Prob\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "204f7ba1",
   "metadata": {},
   "source": [
    "<strong><span style=\"color:Blue\">NOTE:</span></strong> Area under ROC curve is 0.88 out of 1 which indicates a good predictive model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba762fbe",
   "metadata": {},
   "source": [
    "#### Finding Optimal Cutoff Point/ Probability\n",
    "- It is that probability where we get `balanced sensitivity and specificity`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "044e7b50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's create columns with different probability cutoffs \n",
    "numbers = [float(x)/10 for x in range(10)]\n",
    "for i in numbers:\n",
    "    y_train_pred_final[i]= y_train_pred_final['Converted_Prob'].map(lambda x: 1 if x > i else 0)\n",
    "y_train_pred_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "649be686",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now let's calculate accuracy sensitivity and specificity for various probability cutoffs.\n",
    "cutoff_df = pd.DataFrame( columns = ['prob','accuracy','sensi','speci'])\n",
    "\n",
    "# TP = confusion[1,1] # true positive \n",
    "# TN = confusion[0,0] # true negatives\n",
    "# FP = confusion[0,1] # false positives\n",
    "# FN = confusion[1,0] # false negatives\n",
    "\n",
    "num = [float(x)/10 for x in range(10)]\n",
    "for i in num:\n",
    "    cm1 = metrics.confusion_matrix(y_train_pred_final[\"Converted\"], y_train_pred_final[i] )\n",
    "    total1=sum(sum(cm1))\n",
    "    accuracy = (cm1[0,0]+cm1[1,1])/total1\n",
    "    \n",
    "    speci = cm1[0,0]/(cm1[0,0]+cm1[0,1])\n",
    "    sensi = cm1[1,1]/(cm1[1,0]+cm1[1,1])\n",
    "    cutoff_df.loc[i] =[ i ,accuracy,sensi,speci]\n",
    "print(cutoff_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "130bc1fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's plot accuracy sensitivity and specificity for various probabilities.\n",
    "\n",
    "from scipy.interpolate import interp1d\n",
    "from scipy.optimize import fsolve\n",
    "\n",
    "# Finding the intersection points of the sensitivity and accuracy curves\n",
    "sensi_interp = interp1d(cutoff_df['prob'], cutoff_df['sensi'], kind='linear')\n",
    "acc_interp = interp1d(cutoff_df['prob'], cutoff_df['accuracy'], kind='linear')\n",
    "intersection_1 = np.round(float(fsolve(lambda x : sensi_interp(x) - acc_interp(x), 0.5)), 3)\n",
    "\n",
    "# Find the intersection points of the specificity and accuracy curves\n",
    "speci_interp = interp1d(cutoff_df['prob'], cutoff_df['speci'], kind='linear')\n",
    "intersection_2 = np.round(float(fsolve(lambda x : speci_interp(x) - acc_interp(x), 0.5)), 3)\n",
    "\n",
    "# Calculate the average of the two intersection points\n",
    "intersection_x = (intersection_1 + intersection_2) / 2\n",
    "\n",
    "# Interpolate the accuracy, sensitivity, and specificity at the intersection point\n",
    "accuracy_at_intersection = np.round(float(acc_interp(intersection_x)), 2)\n",
    "sensitivity_at_intersection = np.round(float(sensi_interp(intersection_x)), 2)\n",
    "specificity_at_intersection = np.round(float(speci_interp(intersection_x)), 2)\n",
    "\n",
    "# Plot the three curves and add vertical and horizontal lines at intersection point\n",
    "cutoff_df.plot.line(x='prob', y=['accuracy', 'sensi', 'speci'])\n",
    "plt.axvline(x=intersection_x, color='grey',linewidth=0.55, linestyle='--')\n",
    "plt.axhline(y=accuracy_at_intersection, color='grey',linewidth=0.55, linestyle='--')\n",
    "\n",
    "# Adding annotation to display the (x,y) intersection point coordinates \n",
    "plt.annotate(f'({intersection_x} , {accuracy_at_intersection})',\n",
    "             xy=(intersection_x, accuracy_at_intersection),\n",
    "             xytext=(0,20),\n",
    "             textcoords='offset points',\n",
    "             ha='center',\n",
    "             fontsize=9)\n",
    "\n",
    "# Displaying the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cc79505",
   "metadata": {},
   "source": [
    "<strong><span style=\"color:Blue\">NOTE:</span></strong> 0.351 is the approx. point where all the curves meet, so 0.351 seems to be our `Optimal cutoff point` for probability threshold .\n",
    "- Lets do mapping again using optimal cutoff point "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b3cb4eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred_final['final_predicted'] = y_train_pred_final['Converted_Prob'].map( lambda x: 1 if x > 0.351 else 0)\n",
    "\n",
    "# deleting the unwanted columns from dataframe\n",
    "y_train_pred_final.drop([0.0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,\"Predicted\"],axis = 1, inplace = True) \n",
    "y_train_pred_final.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "765a97cb",
   "metadata": {},
   "source": [
    "#### Calculating all metrics using confusion matrix for Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f18df220",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking the overall accuracy.\n",
    "print(metrics.accuracy_score(y_train_pred_final[\"Converted\"], y_train_pred_final[\"final_predicted\"]))\n",
    "\n",
    "# or can be found using confusion matrix with formula, lets find all matrix in one go ahead using UDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c39b64e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# UDF for all Logistic Regression Metrics\n",
    "def logreg_all_metrics(confusion_matrix):\n",
    "    TN =confusion_matrix[0,0]\n",
    "    TP =confusion_matrix[1,1]\n",
    "    FP =confusion_matrix[0,1]\n",
    "    FN =confusion_matrix[1,0]\n",
    "    \n",
    "    accuracy = (TN+TP)/(TN+TP+FN+FP)\n",
    "    sensi = TP/(TP+FN)\n",
    "    speci = TN/(TN+FP)\n",
    "    precision = TP/(TP+FP)\n",
    "    recall = TP/(TP+FN)\n",
    "    TPR = TP/(TP + FN)\n",
    "    TNR = TN/(TN + FP)\n",
    "    \n",
    "    #Calculate false postive rate - predicting conversion when customer does not have converted\n",
    "    FPR = FP/(FP + TN)     \n",
    "    FNR = FN/(FN +TP)\n",
    "    \n",
    "    print (\"True Negative                    : \", TN)\n",
    "    print (\"True Positive                    : \", TP)\n",
    "    print (\"False Negative                   : \", FN)\n",
    "    print (\"False Positve                    : \", FP) \n",
    "    \n",
    "    print (\"Model Accuracy                   : \", round(accuracy,4))\n",
    "    print (\"Model Sensitivity                : \", round(sensi,4))\n",
    "    print (\"Model Specificity                : \", round(speci,4))\n",
    "    print (\"Model Precision                  : \", round(precision,4))\n",
    "    print (\"Model Recall                     : \", round(recall,4))\n",
    "    print (\"Model True Positive Rate (TPR)   : \", round(TPR,4))\n",
    "    print (\"Model False Positive Rate (FPR)  : \", round(FPR,4))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c326eace",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding Confusion metrics for 'y_train_pred_final' df\n",
    "confusion_matrix = metrics.confusion_matrix(y_train_pred_final['Converted'], y_train_pred_final['final_predicted'])\n",
    "print(\"*\"*50,\"\\n\")\n",
    "\n",
    "#\n",
    "print(\"Confusion Matrix\")\n",
    "print(confusion_matrix,\"\\n\")\n",
    "\n",
    "print(\"*\"*50,\"\\n\")\n",
    "\n",
    "# Using UDF to calculate all metrices of logistic regression\n",
    "logreg_all_metrics(confusion_matrix)\n",
    "\n",
    "print(\"\\n\")\n",
    "print(\"*\"*50,\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0ab6903",
   "metadata": {},
   "source": [
    "#### Precision and recall tradeoff\n",
    "- Let's compare all metrics of Precision-Recall view with Specificity-Sensivity view and get better probability threshold for boosting conversion rate to 80% as asked by CEO."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba9a5e9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating precision-recall tradeoff curve\n",
    "y_train_pred_final['Converted'], y_train_pred_final['final_predicted']\n",
    "p, r, thresholds = precision_recall_curve(y_train_pred_final['Converted'], y_train_pred_final['Converted_Prob'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43582cd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot precision-recall tradeoff curve\n",
    "plt.plot(thresholds, p[:-1], \"g-\", label=\"Precision\")\n",
    "plt.plot(thresholds, r[:-1], \"r-\", label=\"Recall\")\n",
    "\n",
    "# add legend and axis labels\n",
    "\n",
    "plt.axvline(x=0.39, color='teal',linewidth = 0.55, linestyle='--')\n",
    "plt.legend(loc='lower left')\n",
    "plt.xlabel('Threshold')\n",
    "plt.ylabel('Precision/Recall')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "388135ef",
   "metadata": {},
   "source": [
    "<strong><span style=\"color:Blue\">NOTE:</span></strong> The intersection point of the curve is the threshold value where the model achieves a balance between precision and recall. It can be used to optimise the performance of the model based on business requirement,Here our probability threshold is 0.39 approx from above curve."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56691290",
   "metadata": {},
   "outputs": [],
   "source": [
    "# copying df to test model evaluation with precision recall threshold of 0.39\n",
    "y_train_precision_recall = y_train_pred_final.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3211cbce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# assigning a feature for 0.41 cutoff from precision recall curve to see which one is best view (sensi-speci or precision-recall)\n",
    "y_train_precision_recall['precision_recall_prediction'] = y_train_precision_recall['Converted_Prob'].map( lambda x: 1 if x > 0.39 else 0)\n",
    "y_train_precision_recall.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c802fdfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Lets see all metrics at 0.39 cutoff in precision-recall view and compare it with 0.351 cutoff from sensi-speci view\n",
    "\n",
    "# Finding Confusion metrics for 'y_train_precision_recall' df\n",
    "confusion_matrix = metrics.confusion_matrix(y_train_precision_recall['Converted'], y_train_precision_recall['precision_recall_prediction'])\n",
    "print(\"*\"*50,\"\\n\")\n",
    "\n",
    "#\n",
    "print(\"Confusion Matrix\")\n",
    "print(confusion_matrix,\"\\n\")\n",
    "\n",
    "print(\"*\"*50,\"\\n\")\n",
    "\n",
    "# Using UDF to calculate all metrices of logistic regression\n",
    "logreg_all_metrics(confusion_matrix)\n",
    "\n",
    "print(\"\\n\")\n",
    "print(\"*\"*50,\"\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0534035",
   "metadata": {},
   "source": [
    "<strong><span style=\"color:Blue\">NOTE:</span></strong> \n",
    "- As we can see in above metrics when we used precision-recall threshold cut-off of 0.39 the values in True Positive Rate ,Sensitivity, Recall have dropped to around 73%, but we need it close to 80% as the Business Objective.\n",
    "- We are getting metric values close to 80% with the sensitivity-specificity cut-off threshold of 0.351. So, we will go with sensitivity-specificity view for our Optimal cut-off for final predictions.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d77558f8",
   "metadata": {},
   "source": [
    "### <strong><span style=\"color:purple\"> Adding `Lead Score` Feature to Training dataframe </span></strong> \n",
    "- A higher score would mean that the lead is hot, i.e. is most likely to convert \n",
    "- Whereas a lower score would mean that the lead is cold and will mostly not get converted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01d483ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets add Lead Score \n",
    "\n",
    "y_train_pred_final['Lead_Score'] = y_train_pred_final['Converted_Prob'].map( lambda x: round(x*100))\n",
    "y_train_pred_final.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8192865",
   "metadata": {},
   "source": [
    "## <p id=\"11\">11. Predictions on Test Set</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89741d1d",
   "metadata": {},
   "source": [
    "#### Scaling Test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8df8ba9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fetching int64 and float64 dtype columns from dataframe for scaling\n",
    "num_cols=X_test.select_dtypes(include=['int64','float64']).columns\n",
    "\n",
    "# scaling columns\n",
    "X_test[num_cols] = scaler.transform(X_test[num_cols])\n",
    "\n",
    "X_test = X_test[rfe_cols]\n",
    "X_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cbec5b7",
   "metadata": {},
   "source": [
    "#### Prediction on Test Dataset using final model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18793f84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding contant value\n",
    "X_test_sm = sm.add_constant(X_test)\n",
    "X_test_sm.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7f4fe95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# making prediction using model 6 (final model)\n",
    "y_test_pred = logm.predict(X_test_sm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a70956f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Changing to dataframe of predicted probability\n",
    "y_test_pred = pd.DataFrame(y_test_pred)\n",
    "y_test_pred.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd222af2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting y_test to dataframe\n",
    "y_test_df = pd.DataFrame(y_test)\n",
    "y_test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f6b535e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Putting Prospect ID to index\n",
    "y_test_df['Prospect ID'] = y_test_df.index\n",
    "\n",
    "# Removing index for both dataframes to append them side by side \n",
    "y_test_pred.reset_index(drop=True, inplace=True)\n",
    "y_test_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Appending y_test_df and y_test_pred\n",
    "y_pred_final = pd.concat([y_test_df, y_test_pred],axis=1)\n",
    "y_pred_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d035652f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Renaming the column \n",
    "y_pred_final= y_pred_final.rename(columns={ 0 : 'Converted_Prob'})\n",
    "\n",
    "# Rearranging the columns\n",
    "y_pred_final = y_pred_final.reindex(['Prospect ID','Converted','Converted_Prob'], axis=1)\n",
    "\n",
    "y_pred_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee7a9e65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# taking sensitivity-specificity method at 0.345 probability cutoff during training\n",
    "y_pred_final['final_predicted'] = y_pred_final['Converted_Prob'].map(lambda x: 1 if x > 0.351 else 0)\n",
    "y_pred_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f3ba0d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drawing ROC curve for Test Set\n",
    "fpr, tpr, thresholds = metrics.roc_curve(y_pred_final[\"Converted\"], y_pred_final[\"Converted_Prob\"], drop_intermediate = False )\n",
    "\n",
    "draw_roc(y_pred_final[\"Converted\"], y_pred_final[\"Converted_Prob\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fed494d",
   "metadata": {},
   "source": [
    "<strong><span style=\"color:Blue\">NOTE:</span></strong> Area under ROC curve is 0.87 out of 1 which indicates a good predictive model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3134f12",
   "metadata": {},
   "source": [
    "<strong><span style=\"color:Blue\">NOTE:</span></strong> \n",
    "- Now that the final predictions have been made, the next step would be to evaluate the performance of the predictive model on a test set. \n",
    "- We will do this by comparing the predicted labels (final_predicted) to the actual labels (Converted) to compute various performance metrics such as accuracy, precision,Â recall,Â etc."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a972796",
   "metadata": {},
   "source": [
    "#### Test set Model Evaluation\n",
    "- Calculating all metrics using confusion matrix for Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69f132a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding Confusion metrics for 'y_train_pred_final' df\n",
    "confusion_matrix = metrics.confusion_matrix(y_pred_final['Converted'], y_pred_final['final_predicted'])\n",
    "print(\"*\"*50,\"\\n\")\n",
    "\n",
    "#\n",
    "print(\"Confusion Matrix\")\n",
    "print(confusion_matrix,\"\\n\")\n",
    "\n",
    "print(\"*\"*50,\"\\n\")\n",
    "\n",
    "# Using UDF to calculate all metrices of logistic regression\n",
    "logreg_all_metrics(confusion_matrix)\n",
    "\n",
    "print(\"\\n\")\n",
    "print(\"*\"*50,\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fdaaa27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# features and their coefficicent from final model\n",
    "parameters=logm.params.sort_values(ascending=False)\n",
    "parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe76e1b3",
   "metadata": {},
   "source": [
    "## <strong><span style=\"color:purple\"> Adding `Lead Score` Feature to Test dataframe </span></strong> \n",
    "- A higher score would mean that the lead is hot, i.e. is most likely to convert \n",
    "- Whereas a lower score would mean that the lead is cold and will mostly not get converted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efffa240",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets add Lead Score \n",
    "\n",
    "y_pred_final['Lead_Score'] = y_pred_final['Converted_Prob'].map( lambda x: round(x*100))\n",
    "y_pred_final.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4111aa61",
   "metadata": {},
   "source": [
    "<strong><span style=\"color:purple\">Lead Score: </span></strong> Lead Score is assigned to the customers\n",
    "- The customers with a higher lead score have a higher conversion chance \n",
    "- The customers with a lower lead score have a lower conversion chance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78dbf8c7",
   "metadata": {},
   "source": [
    "## <p id=\"12\">12. Conclusion</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01cb6f56",
   "metadata": {},
   "source": [
    "## ðŸ“Œ Train - Test\n",
    "### <strong><span style=\"color:purple\">Train Data Set:</span></strong>   \n",
    "\n",
    "- <strong><span style=\"color:Green\">Accuracy:</span></strong> 78.79%\n",
    "\n",
    "- <strong><span style=\"color:Green\">Sensitivity:</span></strong> 77.9%\n",
    "\n",
    "- <strong><span style=\"color:Green\">Specificity:</span></strong> 79.31%\n",
    "\n",
    "### <strong><span style=\"color:purple\">Test Data Set:</span></strong> \n",
    "\n",
    "- <strong><span style=\"color:Green\">Accuracy:</span></strong> 78.72%\n",
    "\n",
    "- <strong><span style=\"color:Green\">Sensitivity:</span></strong> 76.89%\n",
    "\n",
    "- <strong><span style=\"color:Green\">Specificity:</span></strong> 79.99%\n",
    " \n",
    "\n",
    "<strong><span style=\"color:Blue\">NOTE:</span></strong> The evaluation metrics are pretty close to each other so it indicates that the model is performing consistently across different evaluation metrics in both test and train dataset.\n",
    "\n",
    "- The model achieved a `sensitivity of 77.9%` in the train set and 76.89% in the test set, using a cut-off value of 0.351.\n",
    "- Sensitivity in this case indicates how many leads the model identify correctly out of all potential leads which are converting\n",
    "- `The CEO of X Education had set a target sensitivity of around 80%.`\n",
    "- The model also achieved an accuracy of 78%, which is in line with the study's objectives.\n",
    "<hr/>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca1adde6",
   "metadata": {},
   "source": [
    "## ðŸ“ŒModel parameters\n",
    "- The final Logistic Regression Model has 11 features\n",
    "\n",
    "### <strong><span style=\"color:purple\">`Top 3 features` that contributing `positively` to predicting hot leads in the model are:</span></strong> \n",
    "- <strong><span style=\"color:Green\">Lead Source_Welingak Website</span></strong>\n",
    "\n",
    "- <strong><span style=\"color:Green\">Total Time Spent on Website</span></strong> \n",
    "\n",
    "- <strong><span style=\"color:Green\">Occupation_Working Professional</span></strong> \n",
    "\n",
    "<strong><span style=\"color:Blue\">NOTE: </span></strong> The Optimal cutoff probability point is 0.351.Converted probability greater than 0.351 will be predicted as Converted lead (Hot lead) & probability smaller than 0.351 will be predicted as not Converted lead (Cold lead).\n",
    "<hr/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35303392",
   "metadata": {},
   "source": [
    "# âœ…<strong><span style=\"color:brown\">Recommendations </span></strong> \n",
    "\n",
    "### <strong><span style=\"color:purple\">To increase our Lead Conversion Rates: </span></strong>  \n",
    "\n",
    "- Focus on features with positive coefficients for targeted marketing strategies.\n",
    "- Develop strategies to attract high-quality leads from top-performing lead sources.\n",
    "- Engage working professionals with tailored messaging.\n",
    "- Optimize communication channels based on lead engagement impact.\n",
    "- More budget/spend can be done on Welingak Website in terms of advertising, etc.\n",
    "- Incentives/discounts for providing reference that convert to lead, encourage providing more references.\n",
    "- Working professionals to be aggressively targeted as they have high conversion rate and will have better financial situation to pay higher fees too. \n",
    "\n",
    "\n",
    "### <strong><span style=\"color:purple\">To identify areas of improvement: </span></strong>  \n",
    "\n",
    "- Analyze negative coefficients in specialization offerings.\n",
    "- Review landing page submission process for areas of improvement.\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
